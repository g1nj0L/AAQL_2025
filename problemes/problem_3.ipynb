{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a893da8",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING AND QUANTUM COMPUTERS - ASSIGNMENT 1 (26/11/25)\n",
    "\n",
    "## PROBLEM 3\n",
    "\n",
    "> For which distributions does the [68–95–99.7 rule](https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule) hold?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef675096",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "\n",
    "Let's start by importing all the libraries that we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77f8ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf1c05",
   "metadata": {},
   "source": [
    "Also, let's check that all of those packages were correctly installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "405b3978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy's version: 2.3.4\n",
      "Matplot's version: 3.10.7\n",
      "Scipy's version: 1.16.3\n",
      "Pandas's version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numpy's version: {np.__version__}\")\n",
    "print(f\"Matplot's version: {mpl.__version__}\")\n",
    "print(f\"Scipy's version: {sp.__version__}\")\n",
    "print(f\"Pandas's version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3e61fc",
   "metadata": {},
   "source": [
    "As we will use the *68-95-99.7* rule, we'll start by explaining its fundamentals. Then, we'll move on and compute it for the random data we generate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df634ca",
   "metadata": {},
   "source": [
    "### 68-95-99.7 rule\n",
    "\n",
    "$$\\text{Pr}(\\mu-1\\sigma\\leq X\\leq\\mu+1\\sigma)\\approx 68.27\\% $$\n",
    "$$\\text{Pr}(\\mu-2\\sigma\\leq X\\leq\\mu+2\\sigma)\\approx 95.45\\% $$\n",
    "$$\\text{Pr}(\\mu-1\\sigma\\leq X\\leq\\mu+1\\sigma)\\approx 99.73\\% $$\n",
    "\n",
    "This rule, also known as the empirical rule (and sometimes abbreviated $3\\sigma$) is a shorthand used to remember the percentatge of values that lie within an interval estimate in a normal distribution: aprox. 68%, 95% and 99.7% of the values lie within one, two and three standard deviations of the mean, respectively.\n",
    "\n",
    "It's, therefore, a rule that should only work with normal distributions and (because of the central limit theorem) general data sets (i.e., following any probability distribution) with a huge number of elements.\n",
    "\n",
    "### Generating random data\n",
    "\n",
    "Let's generate random data from the different distributions discussed previously. We'll start by defining the function to compute our data sets and its mean and standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0019e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_set(N,mu,sigma,a,b,alpha,beta):\n",
    "    x_normal = np.random.normal(mu,sigma,N)\n",
    "    x_uniform = np.random.uniform(a,b,N)\n",
    "    x_beta = np.random.beta(alpha,beta,N)\n",
    "    x = np.linspace(-10,10,N)\n",
    "\n",
    "    mN = np.mean(x_normal)\n",
    "    sN = np.std(x_normal)\n",
    "\n",
    "    mU = np.mean(x_uniform)\n",
    "    sU = np.std(x_uniform)\n",
    "\n",
    "    mB = np.mean(x_beta)\n",
    "    sB = np.std(x_beta)\n",
    "\n",
    "    return(x_normal,x_uniform,x_beta,x,mN,sN,mU,sU,mB,sB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278ae8de",
   "metadata": {},
   "source": [
    "As we have just seen, our confidence intervals are the following\n",
    "\n",
    "$$\\mu-N\\sigma\\leq X\\leq\\mu+N\\sigma$$\n",
    "\n",
    "with $N\\in\\{1, 2, 3\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c59111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidenceR(sigma=1):\n",
    "    # Gaussian\n",
    "    LciN1 = mN1 - sigma*sN1\n",
    "    RciN1 = mN1 + sigma*sN1\n",
    "    LciN2 = mN2 - sigma*sN2\n",
    "    RciN2 = mN2 + sigma*sN2\n",
    "    LciN3 = mN3 - sigma*sN2\n",
    "    RciN3 = mN3 + sigma*sN2\n",
    "    LciN = [LciN1, LciN2, LciN3]\n",
    "    RciN = [RciN1, RciN2, RciN3]\n",
    "\n",
    "    # Uniform\n",
    "    LciU1 = mU1 - sigma*sU1\n",
    "    RciU1 = mU1 + sigma*sU1\n",
    "    LciU2 = mU2 - sigma*sU2\n",
    "    RciU2 = mU2 + sigma*sU2\n",
    "    LciU3 = mU3 - sigma*sU3\n",
    "    RciU3 = mU3 + sigma*sU3\n",
    "    LciU = [LciU1, LciU2, LciU3]\n",
    "    RciU = [RciU1, RciU2, RciU3]\n",
    "\n",
    "    # Beta\n",
    "    LciB1 = mB1 - sigma*sB1\n",
    "    RciB1 = mB1 + sigma*sB1\n",
    "    LciB2 = mB2 - sigma*sB2\n",
    "    RciB2 = mB2 + sigma*sB2\n",
    "    LciB3 = mB3 - sigma*sB3\n",
    "    RciB3 = mB3 + sigma*sB3\n",
    "    LciB = [LciB1, LciB2, LciB3]\n",
    "    RciB = [RciB1, RciB2, RciB3]\n",
    "\n",
    "    return(LciN, RciN, LciU, RciU, LciB, RciB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e60dcac",
   "metadata": {},
   "source": [
    "And also the function that we will use to present our results in a convenient tabular form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06684140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableR(sigma=[1,2,3]):\n",
    "    LciNt = np.empty((np.size(sigma), 3)) # Change '3' to whichever number of data sets we have!\n",
    "    RciNt = np.empty((np.size(sigma), 3))\n",
    "    LciUt = np.empty((np.size(sigma), 3))\n",
    "    RciUt = np.empty((np.size(sigma), 3))\n",
    "    LciBt = np.empty((np.size(sigma), 3))\n",
    "    RciBt = np.empty((np.size(sigma), 3))\n",
    "    ci = np.empty(np.size(sigma))\n",
    "\n",
    "    for i in range(0,np.size(sigma)):\n",
    "        LciNt[i], RciNt[i], LciUt[i], RciUt[i], LciBt[i], RciBt[i] = confidenceR(sigma=sigma[i])\n",
    "    \n",
    "    ci = [0.6827,0.9945,0.9973]\n",
    "\n",
    "    dataG1 = {\n",
    "        \"CI\": ci,\n",
    "        \"LB N=5000 (G)\": LciNt[:,0],\n",
    "        \"UB N=5000 (G)\": RciNt[:,0]\n",
    "    }\n",
    "    dataG2 = {\n",
    "        \"CI\": ci,\n",
    "        \"LB N=500 (G)\": LciNt[:,1],\n",
    "        \"UB N=500 (G)\": RciNt[:,1]\n",
    "    }\n",
    "    dataG3 = {\n",
    "        \"CI\": ci,\n",
    "        \"LB N=50 (G)\": LciNt[:,2],\n",
    "        \"UB N=50 (G)\": RciNt[:,2]\n",
    "    }\n",
    "\n",
    "    dataU1 = {\n",
    "        \"CI\": ci,\n",
    "        \"LB N=5000 (U)\": LciUt[:,0],\n",
    "        \"UB N=5000 (U)\": RciUt[:,0]\n",
    "    }\n",
    "    dataU2 = {\n",
    "        \"CI\": ci,\n",
    "        \"LB N=500 (U)\": LciUt[:,1],\n",
    "        \"UB N=500 (U)\": RciUt[:,1]\n",
    "    }\n",
    "    dataU3 = {\n",
    "        \"CI\": ci,\n",
    "        \"LB N=50 (U)\": LciUt[:,2],\n",
    "        \"UB N=50 (U)\": RciUt[:,2]\n",
    "    }\n",
    "\n",
    "    dataB1 = {\n",
    "        \"CI\": ci,\n",
    "        \"LB N=5000 (B)\": LciBt[:,0],\n",
    "        \"UB N=5000 (B)\": RciBt[:,0]\n",
    "    }\n",
    "    dataB2 = {\n",
    "        \"CI\": ci,\n",
    "        \"LB N=500 (B)\": LciBt[:,1],\n",
    "        \"UB N=500 (B)\": RciBt[:,1]\n",
    "    }\n",
    "    dataB3 = {\n",
    "        \"CI\": ci,\n",
    "        \"LB N=50 (B)\": LciBt[:,2],\n",
    "        \"UB N=50 (B)\": RciBt[:,2]\n",
    "    }\n",
    "\n",
    "    dfG1 = pd.DataFrame(dataG1)\n",
    "    dfG2 = pd.DataFrame(dataG2)\n",
    "    dfG3 = pd.DataFrame(dataG3)\n",
    "\n",
    "    dfU1 = pd.DataFrame(dataU1)\n",
    "    dfU2 = pd.DataFrame(dataU2)\n",
    "    dfU3 = pd.DataFrame(dataU3)\n",
    "\n",
    "    dfB1 = pd.DataFrame(dataB1)\n",
    "    dfB2 = pd.DataFrame(dataB2)\n",
    "    dfB3 = pd.DataFrame(dataB3)\n",
    "\n",
    "    print(\"[ GAUSSIAN 68-95-99.7 RULE ]\")\n",
    "    print(dfG1)\n",
    "    print(dfG2)\n",
    "    print(dfG3)\n",
    "    print()\n",
    "\n",
    "    print(\"[ UNIFORM 68-95-99.7 RULE ]\")\n",
    "    print(dfU1)\n",
    "    print(dfU2)\n",
    "    print(dfU3)\n",
    "    print()\n",
    "\n",
    "    print(\"[ BETA 68-95-99.7 RULE ]\")\n",
    "    print(dfB1)\n",
    "    print(dfB2)\n",
    "    print(dfB3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d2831",
   "metadata": {},
   "source": [
    "We'll work with two data sets:\n",
    "- One of 5000 elements\n",
    "- One of 500 elements\n",
    "- One of 50 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5534a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_normal1, x_uniform1, x_beta1, x1, mN1, sN1, mU1, sU1, mB1, sB1 = data_set(N = 5000, mu = 0, sigma = 0.6, a = -1, b = 2, alpha = 3, beta = 10)\n",
    "x_normal2, x_uniform2, x_beta2, x2, mN2, sN2, mU2, sU2, mB2, sB2 = data_set(N = 500, mu = 0, sigma = 0.6, a = -1, b = 2, alpha = 3, beta = 10)\n",
    "x_normal3, x_uniform3, x_beta3, x3, mN3, sN3, mU3, sU3, mB3, sB3 = data_set(N = 50, mu = 0, sigma = 0.6, a = -1, b = 2, alpha = 3, beta = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fad6a1",
   "metadata": {},
   "source": [
    "And also our values for $\\sigma$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d061911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef443376",
   "metadata": {},
   "source": [
    "Let's now check our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83589c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ GAUSSIAN 68-95-99.7 RULE ]\n",
      "       CI  LB N=5000 (G)  UB N=5000 (G)\n",
      "0  0.6827      -0.605380       0.609773\n",
      "1  0.9945      -1.212957       1.217350\n",
      "2  0.9973      -1.820534       1.824927\n",
      "       CI  LB N=500 (G)  UB N=500 (G)\n",
      "0  0.6827     -0.615809      0.582357\n",
      "1  0.9945     -1.214892      1.181440\n",
      "2  0.9973     -1.813975      1.780523\n",
      "       CI  LB N=50 (G)  UB N=50 (G)\n",
      "0  0.6827    -0.545197     0.652969\n",
      "1  0.9945    -1.144280     1.252052\n",
      "2  0.9973    -1.743363     1.851135\n",
      "\n",
      "[ UNIFORM 68-95-99.7 RULE ]\n",
      "       CI  LB N=5000 (U)  UB N=5000 (U)\n",
      "0  0.6827      -0.336235       1.371695\n",
      "1  0.9945      -1.190200       2.225660\n",
      "2  0.9973      -2.044165       3.079625\n",
      "       CI  LB N=500 (U)  UB N=500 (U)\n",
      "0  0.6827     -0.380736      1.376837\n",
      "1  0.9945     -1.259523      2.255623\n",
      "2  0.9973     -2.138310      3.134410\n",
      "       CI  LB N=50 (U)  UB N=50 (U)\n",
      "0  0.6827    -0.322810     1.632023\n",
      "1  0.9945    -1.300226     2.609439\n",
      "2  0.9973    -2.277643     3.586856\n",
      "\n",
      "[ BETA 68-95-99.7 RULE ]\n",
      "       CI  LB N=5000 (B)  UB N=5000 (B)\n",
      "0  0.6827       0.116531       0.341194\n",
      "1  0.9945       0.004200       0.453525\n",
      "2  0.9973      -0.108131       0.565856\n",
      "       CI  LB N=500 (B)  UB N=500 (B)\n",
      "0  0.6827      0.120355      0.354748\n",
      "1  0.9945      0.003159      0.471944\n",
      "2  0.9973     -0.114037      0.589141\n",
      "       CI  LB N=50 (B)  UB N=50 (B)\n",
      "0  0.6827     0.142555     0.361113\n",
      "1  0.9945     0.033276     0.470392\n",
      "2  0.9973    -0.076003     0.579671\n"
     ]
    }
   ],
   "source": [
    "tableR(sigma=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b11e60",
   "metadata": {},
   "source": [
    "In general the Gaussian distribution is the one with narrower bounds compared to the other two, as we expected given the definition commented above. Nonetheless, it's curious how those values are *worse* (i.e., bigger) than the ones provided by the Chebishev's interval for the same confidence intervals. Surely, there's some error in our code or some fact about Chebishev's interval that I'm not aware of.\n",
    "\n",
    "Also, we can see that the Uniform and Beta distributions have smaller bounds as we grow our data in size, something that we expected given the central limit theorem: as we grow our data's size, the data will follow a Gaussian distribution, which the 68-95-99.7 rule adapts to better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
